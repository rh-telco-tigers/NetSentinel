# config.yaml

api_config:
  host: "0.0.0.0"
  port: 5000
  debug: true

logging_config:
  level: "DEBUG"

models:
  predictive:
    url: "https://demo-multimodelserver.apps.cluster-76sbq.76sbq.sandbox1319.opentlc.com/v2/models/demo/infer"
    token: ""
    verify_ssl: true
  llm:
    url: "https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1/chat/completions"
    model_name: "granite-8b-code-instruct-128k"
    token: "55ebc201ab5b010dc54974bc36fa1d0a"
    verify_ssl: true
  nlu:
    model_path: "models/rasa/nlu-model.gz"
    num_contexts: 3

milvus:
  host: "localhost"
  port: "19530"
  collection_name: "netsentinel"
  secure: false

slack:
  channel: "#netsentinel"
  bot_token: "xoxb-7834804921362-7828268418118-L0aRQ3CVXKHsjh09De3Oq7nY"
  signing_secret: "8cceb8f82a6a595ce6dca0e689f05e2d"

kafka:
  bootstrap_servers: "netsentinel-kafka-kafka-bootstrap:9092"
  topics:
    raw: "raw-traffic-data"
    processed: "processed-traffic-data"

ocp:
  kubeconfig_path: "/root/.kube/config"
  auth_method: "kubeconfig"
  prometheus_url: "https://thanos-querier.openshift-monitoring.svc.cluster.local:9091"
