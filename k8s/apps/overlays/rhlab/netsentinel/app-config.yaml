# config.yaml

api_config:
  host: "0.0.0.0"
  port: 5000
  debug: true

logging_config:
  level: "DEBUG"

models:
  predictive:
    url: "http://modelmesh-serving.netsentinel:8008/v2/models/netsentinel/infer"
    token: ""
    verify_ssl: true
  llm:
    url: "https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1/chat/completions"
    model_name: "granite-8b-code-instruct-128k"
    token: "<YOUR_API_KEY_HERE>"
    verify_ssl: true
  nlu:
    model_path: "models/rasa/nlu-model.gz"

milvus:
  host: "netsentinel-milvus.milvus-operator.svc.cluster.local"
  port: "19530"
  collection_name: "netsentinel"
  secure: false

slack:
  channel: "#netsentinel"
  bot_token: "<SLACK_BOT_TOKEN_HERE>"
  signing_secret: "<SLACK_SIGNING_SECRET_HERE>"

kafka:
  bootstrap_servers: "console-kafka-kafka-secure-bootstrap:9093"
  topics:
    raw: "raw-traffic-data"
    processed: "processed-traffic-data"

ocp:
  kubeconfig_path: "/root/.kube/config"
  auth_method: "kubeconfig"
  prometheus_url: "https://thanos-querier.openshift-monitoring.svc.cluster.local:9091"
